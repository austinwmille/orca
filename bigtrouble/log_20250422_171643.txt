2025-04-22 17:16:43,525 - INFO - 
==================================================

2025-04-22 17:16:43,525 - INFO - 
script codename: orca

2025-04-22 17:16:43,526 - INFO - 
===============================================================================

2025-04-22 17:17:36,032 - INFO - Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]
2025-04-22 17:17:36,033 - INFO - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []
2025-04-22 17:17:46,698 - INFO - 
===============================================================================

2025-04-22 17:17:46,698 - INFO - packages loaded

2025-04-22 17:17:48,700 - INFO - setting up folders...

2025-04-22 17:17:49,702 - INFO - 'temp' directory named 'imthetrashman'

2025-04-22 17:17:50,704 - INFO - Input folder set to '/app/processmesempai'
2025-04-22 17:17:50,705 - INFO - Clips (output) folder set to '/app/clips'

2025-04-22 17:17:52,708 - INFO - Setting parameters for whisperX. For more details, visit: https://github.com/m-bain/whisperX
2025-04-22 17:17:54,711 - INFO - whisper_arch = 'medium'
device = 'cpu' 
compute_type = 'int8'
language = 'en'

2025-04-22 17:19:00,798 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../usr/local/lib/python3.9/site-packages/whisperx/assets/pytorch_model.bin`
2025-04-22 17:19:00,873 - INFO - next section loads pyannote auth token

2025-04-22 17:19:03,877 - INFO - 
===================================================================

2025-04-22 17:19:05,435 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`
2025-04-22 17:19:05,463 - INFO - Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:05,630 - INFO - Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:06,154 - INFO - Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:09,297 - INFO - Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:09,425 - INFO - Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:09,720 - INFO - Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:09,851 - INFO - Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder
2025-04-22 17:19:10,390 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`
2025-04-22 17:19:10,416 - INFO - Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:10,485 - INFO - Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:10,763 - INFO - Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:10,844 - INFO - Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:10,915 - INFO - Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:10,999 - INFO - Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-22 17:19:11,250 - INFO - Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder
2025-04-22 17:19:11,397 - INFO - 
===================================================================

2025-04-22 17:19:11,398 - INFO - setup completed.

2025-04-22 17:19:13,404 - INFO - 
we will now begin processing 1 media files

2025-04-22 17:19:15,964 - INFO - 
The time required varies hugely on your computing hardware and selected parameters.

2025-04-22 17:19:15,965 - INFO - Good luck ;/

2025-04-22 17:19:15,967 - INFO - 
===============================

2025-04-22 17:19:15,990 - INFO - Processing video/audio file: /app/processmesempai/Jordan_Peterson_on_Andrew_Tate___Lex_Fridman_Podcast_Clips.mp4
2025-04-22 17:19:28,484 - INFO - Audio extracted to: imthetrashman/Jordan_Peterson_on_Andrew_Tate___Lex_Fridman_Podcast_Clips_audio.wav
2025-04-22 17:28:40,099 - INFO - Diarization completed. Retrieved speaker segments.
[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
/usr/local/lib/python3.9/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)
  std = sequences.std(dim=-1, correction=1)
Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cu121. Bad things might happen unless you revert torch to 1.x.
Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cu121. Bad things might happen unless you revert torch to 1.x.
Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cu121. Bad things might happen unless you revert torch to 1.x.
Segmenting audio:   0%|          | 0/12 [00:00<?, ?it/s]Segmenting audio: 100%|██████████| 12/12 [00:00<00:00, 120699.40it/s]2025-04-22 17:28:45,629 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../usr/local/lib/python3.9/site-packages/whisperx/assets/pytorch_model.bin`

Downloading: "https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ls960.pth" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960_asr_ls960.pth
No language specified, language will be first be detected for each audio file (increases inference time).
Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cu121. Bad things might happen unless you revert torch to 1.x.
  0%|          | 0.00/360M [00:00<?, ?B/s]  0%|          | 560k/360M [00:00<01:06, 5.65MB/s]  1%|          | 2.51M/360M [00:00<00:26, 14.3MB/s]  1%|▏         | 4.90M/360M [00:00<00:19, 19.0MB/s]  2%|▏         | 7.19M/360M [00:00<00:17, 21.0MB/s]  3%|▎         | 9.55M/360M [00:00<00:16, 22.1MB/s]  3%|▎         | 11.7M/360M [00:00<00:16, 22.0MB/s]  4%|▍         | 13.8M/360M [00:00<00:16, 21.7MB/s]  4%|▍         | 15.8M/360M [00:00<00:17, 20.5MB/s]  5%|▍         | 18.0M/360M [00:00<00:17, 21.0MB/s]  6%|▌         | 20.3M/360M [00:01<00:16, 22.0MB/s]  6%|▋         | 22.6M/360M [00:01<00:15, 22.2MB/s]  7%|▋         | 24.7M/360M [00:01<00:15, 22.3MB/s]  7%|▋         | 27.0M/360M [00:01<00:15, 22.6MB/s]  8%|▊         | 29.1M/360M [00:01<00:15, 22.6MB/s]  9%|▊         | 31.3M/360M [00:01<00:16, 20.8MB/s]  9%|▉         | 33.3M/360M [00:01<00:16, 20.5MB/s] 10%|▉         | 35.3M/360M [00:01<00:17, 19.0MB/s] 10%|█         | 37.1M/360M [00:01<00:18, 18.3MB/s] 11%|█         | 39.2M/360M [00:02<00:17, 19.1MB/s] 12%|█▏        | 41.5M/360M [00:02<00:16, 20.3MB/s] 12%|█▏        | 43.5M/360M [00:02<00:17, 18.6MB/s] 13%|█▎        | 45.3M/360M [00:02<00:17, 18.6MB/s] 13%|█▎        | 47.3M/360M [00:02<00:17, 19.3MB/s] 14%|█▎        | 49.2M/360M [00:02<00:17, 18.5MB/s] 14%|█▍        | 51.5M/360M [00:02<00:16, 20.1MB/s] 15%|█▍        | 53.4M/360M [00:02<00:15, 20.1MB/s] 15%|█▌        | 55.4M/360M [00:02<00:16, 19.1MB/s] 16%|█▌        | 57.2M/360M [00:03<00:18, 17.6MB/s] 16%|█▋        | 59.3M/360M [00:03<00:16, 18.7MB/s] 17%|█▋        | 61.3M/360M [00:03<00:16, 18.9MB/s] 18%|█▊        | 63.1M/360M [00:03<00:16, 19.0MB/s] 18%|█▊        | 65.2M/360M [00:03<00:15, 19.8MB/s] 19%|█▊        | 67.3M/360M [00:03<00:15, 20.1MB/s] 19%|█▉        | 69.2M/360M [00:03<00:15, 19.5MB/s] 20%|█▉        | 71.1M/360M [00:03<00:15, 19.2MB/s] 20%|██        | 73.1M/360M [00:03<00:15, 19.7MB/s] 21%|██        | 75.3M/360M [00:03<00:14, 20.6MB/s] 22%|██▏       | 78.1M/360M [00:04<00:12, 23.3MB/s] 22%|██▏       | 80.4M/360M [00:04<00:12, 22.9MB/s] 23%|██▎       | 82.6M/360M [00:04<00:13, 21.2MB/s] 24%|██▎       | 84.7M/360M [00:04<00:13, 21.6MB/s] 24%|██▍       | 86.8M/360M [00:04<00:14, 19.3MB/s] 25%|██▍       | 89.3M/360M [00:04<00:13, 21.1MB/s] 25%|██▌       | 91.6M/360M [00:04<00:13, 21.5MB/s] 26%|██▌       | 93.7M/360M [00:04<00:13, 21.2MB/s] 27%|██▋       | 95.9M/360M [00:04<00:12, 21.8MB/s] 27%|██▋       | 98.0M/360M [00:05<00:14, 19.5MB/s] 28%|██▊       | 100M/360M [00:05<00:13, 20.4MB/s]  29%|██▊       | 103M/360M [00:05<00:12, 21.8MB/s] 29%|██▉       | 105M/360M [00:05<00:12, 21.0MB/s] 30%|██▉       | 108M/360M [00:05<00:11, 23.6MB/s] 31%|███       | 110M/360M [00:05<00:11, 23.4MB/s] 31%|███▏      | 113M/360M [00:05<00:10, 25.7MB/s] 32%|███▏      | 116M/360M [00:05<00:09, 27.2MB/s] 33%|███▎      | 119M/360M [00:05<00:10, 25.0MB/s] 34%|███▎      | 121M/360M [00:06<00:10, 24.6MB/s] 34%|███▍      | 123M/360M [00:06<00:10, 23.3MB/s] 35%|███▍      | 126M/360M [00:06<00:10, 23.2MB/s] 36%|███▌      | 128M/360M [00:06<00:10, 24.1MB/s] 36%|███▌      | 130M/360M [00:06<00:10, 22.7MB/s] 37%|███▋      | 133M/360M [00:06<00:10, 23.4MB/s] 38%|███▊      | 135M/360M [00:06<00:10, 22.0MB/s] 38%|███▊      | 137M/360M [00:06<00:10, 21.5MB/s] 39%|███▊      | 139M/360M [00:06<00:10, 21.5MB/s] 39%|███▉      | 141M/360M [00:07<00:10, 21.3MB/s] 40%|████      | 144M/360M [00:07<00:09, 23.1MB/s] 41%|████      | 146M/360M [00:07<00:09, 22.6MB/s] 41%|████▏     | 149M/360M [00:07<00:10, 21.9MB/s] 42%|████▏     | 151M/360M [00:07<00:09, 23.1MB/s] 43%|████▎     | 154M/360M [00:07<00:09, 23.8MB/s] 43%|████▎     | 156M/360M [00:07<00:09, 22.4MB/s] 44%|████▍     | 158M/360M [00:07<00:09, 22.9MB/s] 45%|████▍     | 160M/360M [00:07<00:09, 23.0MB/s] 45%|████▌     | 163M/360M [00:08<00:09, 21.4MB/s] 46%|████▌     | 165M/360M [00:08<00:09, 22.1MB/s] 46%|████▋     | 167M/360M [00:08<00:09, 22.2MB/s] 47%|████▋     | 169M/360M [00:08<00:08, 22.4MB/s] 48%|████▊     | 172M/360M [00:08<00:08, 24.0MB/s] 48%|████▊     | 174M/360M [00:08<00:08, 22.9MB/s] 49%|████▉     | 177M/360M [00:08<00:08, 22.1MB/s] 50%|████▉     | 179M/360M [00:08<00:08, 22.4MB/s] 50%|█████     | 181M/360M [00:08<00:08, 22.5MB/s] 51%|█████     | 183M/360M [00:08<00:08, 22.4MB/s] 52%|█████▏    | 186M/360M [00:09<00:07, 23.1MB/s] 52%|█████▏    | 189M/360M [00:09<00:07, 25.5MB/s] 53%|█████▎    | 191M/360M [00:09<00:07, 24.6MB/s] 54%|█████▍    | 195M/360M [00:09<00:06, 28.4MB/s] 55%|█████▍    | 198M/360M [00:09<00:06, 28.0MB/s] 56%|█████▌    | 200M/360M [00:09<00:06, 27.8MB/s] 56%|█████▋    | 203M/360M [00:09<00:05, 27.7MB/s] 57%|█████▋    | 206M/360M [00:09<00:05, 29.5MB/s] 58%|█████▊    | 209M/360M [00:09<00:05, 29.0MB/s] 59%|█████▉    | 212M/360M [00:10<00:05, 29.1MB/s] 60%|█████▉    | 215M/360M [00:10<00:05, 27.7MB/s] 60%|██████    | 217M/360M [00:10<00:05, 26.2MB/s] 61%|██████    | 220M/360M [00:10<00:05, 24.7MB/s] 62%|██████▏   | 222M/360M [00:10<00:06, 23.5MB/s] 62%|██████▏   | 225M/360M [00:10<00:06, 23.4MB/s] 63%|██████▎   | 227M/360M [00:10<00:05, 23.4MB/s] 64%|██████▎   | 229M/360M [00:10<00:05, 23.7MB/s] 65%|██████▍   | 232M/360M [00:10<00:05, 26.0MB/s] 65%|██████▌   | 235M/360M [00:11<00:04, 27.5MB/s] 66%|██████▋   | 239M/360M [00:11<00:04, 29.7MB/s] 67%|██████▋   | 242M/360M [00:11<00:04, 27.9MB/s] 68%|██████▊   | 244M/360M [00:11<00:04, 28.1MB/s] 69%|██████▊   | 247M/360M [00:11<00:04, 26.9MB/s] 69%|██████▉   | 250M/360M [00:11<00:04, 26.0MB/s] 70%|███████   | 252M/360M [00:11<00:04, 25.3MB/s] 71%|███████   | 255M/360M [00:11<00:04, 23.7MB/s] 71%|███████▏  | 257M/360M [00:11<00:04, 24.1MB/s] 72%|███████▏  | 260M/360M [00:12<00:04, 24.6MB/s] 73%|███████▎  | 262M/360M [00:12<00:04, 24.5MB/s] 74%|███████▎  | 265M/360M [00:12<00:03, 26.8MB/s] 74%|███████▍  | 268M/360M [00:12<00:03, 25.9MB/s] 75%|███████▌  | 271M/360M [00:12<00:03, 27.9MB/s] 76%|███████▌  | 274M/360M [00:12<00:03, 28.1MB/s] 77%|███████▋  | 276M/360M [00:12<00:03, 27.0MB/s] 77%|███████▋  | 279M/360M [00:12<00:03, 26.7MB/s] 78%|███████▊  | 281M/360M [00:12<00:03, 26.8MB/s] 79%|███████▉  | 285M/360M [00:12<00:02, 28.4MB/s] 80%|███████▉  | 287M/360M [00:13<00:02, 26.1MB/s] 81%|████████  | 290M/360M [00:13<00:02, 26.2MB/s] 81%|████████  | 292M/360M [00:13<00:02, 25.0MB/s] 82%|████████▏ | 295M/360M [00:13<00:02, 24.7MB/s] 83%|████████▎ | 297M/360M [00:13<00:02, 25.0MB/s] 83%|████████▎ | 300M/360M [00:13<00:02, 23.8MB/s] 84%|████████▍ | 303M/360M [00:13<00:02, 25.7MB/s] 85%|████████▍ | 305M/360M [00:13<00:02, 26.0MB/s] 86%|████████▌ | 309M/360M [00:13<00:01, 28.3MB/s] 86%|████████▋ | 311M/360M [00:14<00:01, 28.2MB/s] 87%|████████▋ | 315M/360M [00:14<00:01, 29.9MB/s] 88%|████████▊ | 318M/360M [00:14<00:01, 30.6MB/s] 89%|████████▉ | 321M/360M [00:14<00:01, 31.0MB/s] 90%|████████▉ | 324M/360M [00:14<00:01, 29.7MB/s] 91%|█████████ | 326M/360M [00:14<00:01, 27.4MB/s] 91%|█████████▏| 329M/360M [00:14<00:01, 26.1MB/s] 92%|█████████▏| 332M/360M [00:14<00:01, 26.3MB/s] 93%|█████████▎| 334M/360M [00:14<00:01, 25.2MB/s] 93%|█████████▎| 337M/360M [00:15<00:01, 23.7MB/s] 94%|█████████▍| 340M/360M [00:15<00:00, 26.2MB/s] 95%|█████████▌| 342M/360M [00:15<00:00, 26.6MB/s] 96%|█████████▌| 346M/360M [00:15<00:00, 28.9MB/s] 97%|█████████▋| 349M/360M [00:15<00:00, 29.0MB/s] 98%|█████████▊| 352M/360M [00:15<00:00, 29.9MB/s] 98%|█████████▊| 355M/360M [00:15<00:00, 29.6MB/s] 99%|█████████▉| 357M/360M [00:15<00:00, 25.8MB/s]100%|█████████▉| 360M/360M [00:15<00:00, 25.2MB/s]100%|██████████| 360M/360M [00:15<00:00, 23.7MB/s]2025-04-22 17:35:00,886 - INFO - Use pytorch device_name: cpu
2025-04-22 17:35:00,887 - INFO - Load pretrained SentenceTransformer: all-roberta-large-v1

/usr/local/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:09<00:09,  9.16s/it]Batches: 100%|██████████| 2/2 [00:11<00:00,  5.18s/it]Batches: 100%|██████████| 2/2 [00:11<00:00,  5.78s/it]2025-04-22 17:36:12,935 - INFO - Clip 1: Start=2.97, End=56.196
2025-04-22 17:36:12,936 - INFO - Clip 2: Start=54.796, End=134.09
2025-04-22 17:36:12,936 - INFO - Clip 3: Start=139.794, End=216.214
2025-04-22 17:36:12,937 - INFO - Clip 4: Start=220.42, End=277.8
2025-04-22 17:36:12,938 - INFO - Clip 5: Start=273.558, End=322.612
2025-04-22 17:36:12,938 - INFO - Clip 6: Start=126.465, End=206.744
2025-04-22 17:36:12,939 - INFO - Clip 7: Start=203.343, End=224.185
2025-04-22 17:36:12,939 - INFO - Processing clip 1: -> /app/clips/Jordan_Peterson_on_Andrew_Tate___Lex_Fridman_Podcast_Clips/Jordan_Peterson_on_Andrew_Tate___Lex_Fridman_Podcast_Clips_clip1.mp4
2025-04-22 17:36:12,940 - INFO - → About to call resize() for clip 1
2025-04-22 17:44:49,276 - INFO - Detecting scenes...
2025-04-22 17:50:13,027 - INFO - ← resize() returned in 840.1s
2025-04-22 17:50:13,028 - INFO - Segments for clip 1: [{'start_time': 0.0, 'end_time': 7.06666, 'x': 283, 'y': 0}, {'start_time': 7.06666, 'end_time': 11.599989, 'x': 1058, 'y': 0}, {'start_time': 11.599989, 'end_time': 14.13332, 'x': 365, 'y': 0}, {'start_time': 14.13332, 'end_time': 115.466554, 'x': 1011, 'y': 0}, {'start_time': 115.466554, 'end_time': 126.266544, 'x': 360, 'y': 0}, {'start_time': 126.266544, 'end_time': 151.06652, 'x': 999, 'y': 0}, {'start_time': 151.06652, 'end_time': 158.633179, 'x': 657, 'y': 0}, {'start_time': 158.633179, 'end_time': 203.099802, 'x': 1045, 'y': 0}, {'start_time': 203.099802, 'end_time': 207.099799, 'x': 305, 'y': 0}, {'start_time': 207.099799, 'end_time': 210.466462, 'x': 1067, 'y': 0}, {'start_time': 210.466462, 'end_time': 216.266456, 'x': 324, 'y': 0}, {'start_time': 216.266456, 'end_time': 220.466452, 'x': 1077, 'y': 11}, {'start_time': 220.466452, 'end_time': 220.975344, 'x': 1180, 'y': 11}, {'start_time': 220.975344, 'end_time': 251.233089, 'x': 312, 'y': 0}, {'start_time': 251.233089, 'end_time': 256.133084, 'x': 992, 'y': 0}, {'start_time': 256.133084, 'end_time': 265.933075, 'x': 349, 'y': 0}, {'start_time': 265.933075, 'end_time': 271.499736, 'x': 1030, 'y': 0}, {'start_time': 271.499736, 'end_time': 273.166401, 'x': 352, 'y': 0}, {'start_time': 273.166401, 'end_time': 306.299702, 'x': 1014, 'y': 0}, {'start_time': 306.299702, 'end_time': 317.233025, 'x': 367, 'y': 0}, {'start_time': 317.233025, 'end_time': 318.766357, 'x': 1024, 'y': 0}, {'start_time': 318.766357, 'end_time': 321.066354, 'x': 340, 'y': 0}, {'start_time': 321.066354, 'end_time': 342.741, 'x': 109, 'y': 143}]
2025-04-22 18:00:20,722 - ERROR - Error in FFmpeg command for concatenating segments. Here is some helpful troubleshooting information:
 Terminal return code: '1'
Output: ''
Err Output: 'ffmpeg version 5.1.6-0+deb12u1 Copyright (c) 2000-2024 the FFmpeg developers
  built with gcc 12 (Debian 12.2.0-14)
  configuration: --prefix=/usr --extra-version=0+deb12u1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librist --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --disable-sndio --enable-libjxl --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-libplacebo --enable-librav1e --enable-shared
  libavutil      57. 28.100 / 57. 28.100
  libavcodec     59. 37.100 / 59. 37.100
  libavformat    59. 27.100 / 59. 27.100
  libavdevice    59.  7.100 / 59.  7.100
  libavfilter     8. 44.100 /  8. 44.100
  libswscale      6.  7.100 /  6.  7.100
  libswresample   4.  7.100 /  4.  7.100
  libpostproc    56.  6.100 / 56.  6.100
[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55ced4c88540] Auto-inserting h264_mp4toannexb bitstream filter
Input #0, concat, from '/usr/local/lib/python3.9/site-packages/clipsai/media/aa2a86d9a5e94ef891410435136d7120_media_file_paths.txt':
  Duration: N/A, start: -0.014833, bitrate: 1161 kb/s
  Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 606x1080 [SAR 1:1 DAR 101:180], 1086 kb/s, 30 fps, 30 tbr, 15360 tbn
    Metadata:
      handler_name    : VideoHandler
      vendor_id       : [0][0][0][0]
      encoder         : Lavc59.37.100 libx264
  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 75 kb/s
    Metadata:
      handler_name    : SoundHandler
      vendor_id       : [0][0][0][0]
Filtergraph 'setpts=PTS-STARTPTS' was defined for video output stream 0:0 but codec copy was selected.
Filtering and streamcopy cannot be used together.
'

2025-04-22 18:01:13,330 - INFO - Resized clip 1 saved to: /app/clips/Jordan_Peterson_on_Andrew_Tate___Lex_Fridman_Podcast_Clips/Jordan_Peterson_on_Andrew_Tate___Lex_Fridman_Podcast_Clips_clip1.mp4
2025-04-22 18:01:13,331 - INFO - Processing clip 2: -> /app/clips/Jordan_Peterson_on_Andrew_Tate___Lex_Fridman_Podcast_Clips/Jordan_Peterson_on_Andrew_Tate___Lex_Fridman_Podcast_Clips_clip2.mp4
2025-04-22 18:01:13,332 - INFO - → About to call resize() for clip 2

/usr/local/lib/python3.9/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)
  std = sequences.std(dim=-1, correction=1)
/usr/local/lib/python3.9/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)
  std = sequences.std(dim=-1, correction=1)
Traceback (most recent call last):
  File "/app/orca.py", line 310, in <module>
    crops = resize(
  File "/usr/local/lib/python3.9/site-packages/clipsai/resize/resize.py", line 78, in resize
    diarized_segments = diarizer.diarize(media, min_segment_duration, time_precision)
  File "/usr/local/lib/python3.9/site-packages/clipsai/diarize/pyannote.py", line 107, in diarize
    pyannote_segments: Annotation = self.pipeline({"audio": wav_file.path})
  File "/usr/local/lib/python3.9/site-packages/pyannote/audio/core/pipeline.py", line 327, in __call__
    return self.apply(file, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/pyannote/audio/pipelines/speaker_diarization.py", line 523, in apply
    embeddings = self.get_embeddings(
  File "/usr/local/lib/python3.9/site-packages/pyannote/audio/pipelines/speaker_diarization.py", line 348, in get_embeddings
    embedding_batch: np.ndarray = self._embedding(
  File "/usr/local/lib/python3.9/site-packages/pyannote/audio/pipelines/speaker_verification.py", line 702, in __call__
    embeddings = self.model_(
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/pyannote/audio/models/embedding/wespeaker/__init__.py", line 343, in forward
    return self.resnet(fbank, weights=weights)[1]
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/pyannote/audio/models/embedding/wespeaker/resnet.py", line 416, in forward
    out = self.layer1(out)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/pyannote/audio/models/embedding/wespeaker/resnet.py", line 141, in forward
    out = F.relu(self.bn1(self.conv1(x)))
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
KeyboardInterrupt
2025-04-22 18:07:10,834 - INFO - >>> SCRIPT IS EXITING NOW <<<
